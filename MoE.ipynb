{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from balm.data import load_dataset, DataCollator\n",
    "from balm.models import BalmMoEForMaskedLM\n",
    "from balm.tokenizer import Tokenizer\n",
    "from balm.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=\"./vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sep(txt):\n",
    "    return txt.replace(\"</s>\", \"<cls><cls>\")\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"./balm/test_data/test.txt\",\n",
    "    \"test\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"eval\": \"./balm/test_data/test_1k.txt\",\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=data_files, preprocess_fn=remove_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca587dcc6d804d6abd3081158cb1f29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66792 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d9cab8e30444878d076574b2724e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1555a9edeb84313b13d3b85dccf3829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        x[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=320,\n",
    "    ),\n",
    "    remove_columns=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollator(tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BalmMoERoPEForMaskedLM(\n",
    "model = BalmMoEForMaskedLM(\n",
    "    embed_dim=256,\n",
    "    ffn_dim=1024,\n",
    "    num_experts=4,\n",
    "    num_shared_experts=0,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    alternate_sparsity=True,\n",
    "    router_top_k=1,\n",
    "    # router_class=ExpertChoiceRouter,\n",
    "    expert_capacity=128,\n",
    "    # expert_capacity=128,\n",
    "    router_z_loss_coef=0.01,\n",
    "    # router_aux_loss_coef=0.01,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12692257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"eval\"],\n",
    "    epochs=1,\n",
    "    logging_steps=10,\n",
    "    eval_steps=50,\n",
    "    warmup_steps=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    # per_device_eval_batch_size=32,\n",
    "    use_cpu=True,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48d566dc63d4ea3a60a18b29a8651fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10   | loss: 3.0536 | lm_loss: 3.0292 | router_z_loss: 0.0223 | router_aux_loss: 0.0022 | lr: 0.000080\n",
      "step 20   | loss: 2.8129 | lm_loss: 2.7974 | router_z_loss: 0.0134 | router_aux_loss: 0.0021 | lr: 0.000160\n",
      "step 30   | loss: 2.6459 | lm_loss: 2.6383 | router_z_loss: 0.0056 | router_aux_loss: 0.0019 | lr: 0.000240\n",
      "step 40   | loss: 2.4792 | lm_loss: 2.4734 | router_z_loss: 0.0039 | router_aux_loss: 0.0019 | lr: 0.000320\n",
      "step 50   | loss: 2.2892 | lm_loss: 2.2847 | router_z_loss: 0.0026 | router_aux_loss: 0.0019 | lr: 0.000400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c614b369b165474e926bd580a5bf5a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 2.2572\n",
      "step 60   | loss: 2.1936 | lm_loss: 2.1902 | router_z_loss: 0.0018 | router_aux_loss: 0.0017 | lr: 0.000398\n",
      "step 70   | loss: 2.0466 | lm_loss: 2.0437 | router_z_loss: 0.0014 | router_aux_loss: 0.0016 | lr: 0.000396\n",
      "step 80   | loss: 2.1281 | lm_loss: 2.1253 | router_z_loss: 0.0012 | router_aux_loss: 0.0016 | lr: 0.000394\n",
      "step 90   | loss: 2.0680 | lm_loss: 2.0652 | router_z_loss: 0.0012 | router_aux_loss: 0.0016 | lr: 0.000392\n",
      "step 100  | loss: 2.0606 | lm_loss: 2.0583 | router_z_loss: 0.0009 | router_aux_loss: 0.0014 | lr: 0.000390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe5c87ce44445c2af4cd3e40c8314a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 2.0198\n",
      "step 110  | loss: 1.9348 | lm_loss: 1.9323 | router_z_loss: 0.0012 | router_aux_loss: 0.0013 | lr: 0.000388\n",
      "step 120  | loss: 1.9943 | lm_loss: 1.9921 | router_z_loss: 0.0009 | router_aux_loss: 0.0013 | lr: 0.000386\n",
      "step 130  | loss: 2.0311 | lm_loss: 2.0289 | router_z_loss: 0.0009 | router_aux_loss: 0.0013 | lr: 0.000384\n",
      "step 140  | loss: 1.9543 | lm_loss: 1.9521 | router_z_loss: 0.0008 | router_aux_loss: 0.0014 | lr: 0.000382\n",
      "step 150  | loss: 1.9783 | lm_loss: 1.9763 | router_z_loss: 0.0007 | router_aux_loss: 0.0013 | lr: 0.000380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f689f85e241e49b28dd2716a4bfc6510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.9263\n",
      "step 160  | loss: 2.0417 | lm_loss: 2.0399 | router_z_loss: 0.0006 | router_aux_loss: 0.0012 | lr: 0.000378\n",
      "step 170  | loss: 1.9179 | lm_loss: 1.9161 | router_z_loss: 0.0006 | router_aux_loss: 0.0012 | lr: 0.000376\n",
      "step 180  | loss: 1.9228 | lm_loss: 1.9208 | router_z_loss: 0.0007 | router_aux_loss: 0.0012 | lr: 0.000374\n",
      "step 190  | loss: 1.8958 | lm_loss: 1.8940 | router_z_loss: 0.0006 | router_aux_loss: 0.0012 | lr: 0.000373\n",
      "step 200  | loss: 1.8689 | lm_loss: 1.8672 | router_z_loss: 0.0005 | router_aux_loss: 0.0011 | lr: 0.000371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cfa8e5a5a3482ba6afdcab76639da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.8689\n",
      "step 210  | loss: 1.8817 | lm_loss: 1.8800 | router_z_loss: 0.0006 | router_aux_loss: 0.0011 | lr: 0.000369\n",
      "step 220  | loss: 1.8877 | lm_loss: 1.8862 | router_z_loss: 0.0005 | router_aux_loss: 0.0011 | lr: 0.000367\n",
      "step 230  | loss: 1.7258 | lm_loss: 1.7238 | router_z_loss: 0.0009 | router_aux_loss: 0.0011 | lr: 0.000365\n",
      "step 240  | loss: 1.8583 | lm_loss: 1.8568 | router_z_loss: 0.0004 | router_aux_loss: 0.0011 | lr: 0.000363\n",
      "step 250  | loss: 1.8388 | lm_loss: 1.8372 | router_z_loss: 0.0005 | router_aux_loss: 0.0011 | lr: 0.000361\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f16fdc962343b8b1501f1271aefd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.7606\n",
      "step 260  | loss: 1.7136 | lm_loss: 1.7119 | router_z_loss: 0.0007 | router_aux_loss: 0.0011 | lr: 0.000359\n",
      "step 270  | loss: 1.7217 | lm_loss: 1.7201 | router_z_loss: 0.0006 | router_aux_loss: 0.0011 | lr: 0.000357\n",
      "step 280  | loss: 1.5930 | lm_loss: 1.5913 | router_z_loss: 0.0006 | router_aux_loss: 0.0011 | lr: 0.000355\n",
      "step 290  | loss: 1.6847 | lm_loss: 1.6833 | router_z_loss: 0.0005 | router_aux_loss: 0.0010 | lr: 0.000353\n",
      "step 300  | loss: 1.6752 | lm_loss: 1.6737 | router_z_loss: 0.0005 | router_aux_loss: 0.0010 | lr: 0.000351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24c1890dd1541b896cf0d2fddd3dbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.6471\n",
      "step 310  | loss: 1.5373 | lm_loss: 1.5358 | router_z_loss: 0.0005 | router_aux_loss: 0.0010 | lr: 0.000349\n",
      "step 320  | loss: 1.6273 | lm_loss: 1.6259 | router_z_loss: 0.0004 | router_aux_loss: 0.0010 | lr: 0.000347\n",
      "step 330  | loss: 1.6251 | lm_loss: 1.6236 | router_z_loss: 0.0005 | router_aux_loss: 0.0010 | lr: 0.000345\n",
      "step 340  | loss: 1.5961 | lm_loss: 1.5948 | router_z_loss: 0.0004 | router_aux_loss: 0.0009 | lr: 0.000343\n",
      "step 350  | loss: 1.5413 | lm_loss: 1.5399 | router_z_loss: 0.0004 | router_aux_loss: 0.0009 | lr: 0.000341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d9f2fdce284d5eb92dd066ee777592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.5161\n",
      "step 360  | loss: 1.4912 | lm_loss: 1.4897 | router_z_loss: 0.0005 | router_aux_loss: 0.0010 | lr: 0.000339\n",
      "step 370  | loss: 1.4821 | lm_loss: 1.4806 | router_z_loss: 0.0005 | router_aux_loss: 0.0010 | lr: 0.000337\n",
      "step 380  | loss: 1.4715 | lm_loss: 1.4701 | router_z_loss: 0.0004 | router_aux_loss: 0.0009 | lr: 0.000335\n",
      "step 390  | loss: 1.5111 | lm_loss: 1.5097 | router_z_loss: 0.0005 | router_aux_loss: 0.0009 | lr: 0.000333\n",
      "step 400  | loss: 1.3675 | lm_loss: 1.3661 | router_z_loss: 0.0005 | router_aux_loss: 0.0009 | lr: 0.000331\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73873b6eb50f4afca0f19601a390afe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.3839\n",
      "step 410  | loss: 1.2987 | lm_loss: 1.2974 | router_z_loss: 0.0004 | router_aux_loss: 0.0009 | lr: 0.000329\n",
      "step 420  | loss: 1.3694 | lm_loss: 1.3680 | router_z_loss: 0.0005 | router_aux_loss: 0.0009 | lr: 0.000327\n",
      "step 430  | loss: 1.3263 | lm_loss: 1.3250 | router_z_loss: 0.0004 | router_aux_loss: 0.0009 | lr: 0.000325\n",
      "step 440  | loss: 1.2712 | lm_loss: 1.2700 | router_z_loss: 0.0004 | router_aux_loss: 0.0008 | lr: 0.000323\n",
      "step 450  | loss: 1.3931 | lm_loss: 1.3919 | router_z_loss: 0.0003 | router_aux_loss: 0.0008 | lr: 0.000321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7069c6d30c71457f8624e95d068932a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.2469\n",
      "step 460  | loss: 1.2199 | lm_loss: 1.2186 | router_z_loss: 0.0005 | router_aux_loss: 0.0008 | lr: 0.000319\n",
      "step 470  | loss: 1.2565 | lm_loss: 1.2554 | router_z_loss: 0.0004 | router_aux_loss: 0.0007 | lr: 0.000318\n",
      "step 480  | loss: 1.2974 | lm_loss: 1.2963 | router_z_loss: 0.0004 | router_aux_loss: 0.0007 | lr: 0.000316\n",
      "step 490  | loss: 1.2020 | lm_loss: 1.2009 | router_z_loss: 0.0004 | router_aux_loss: 0.0007 | lr: 0.000314\n",
      "step 500  | loss: 1.0745 | lm_loss: 1.0734 | router_z_loss: 0.0003 | router_aux_loss: 0.0008 | lr: 0.000312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73d59f9650e44d6bc5cf6627781e68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.1442\n",
      "step 510  | loss: 1.2005 | lm_loss: 1.1995 | router_z_loss: 0.0003 | router_aux_loss: 0.0007 | lr: 0.000310\n",
      "step 520  | loss: 1.0898 | lm_loss: 1.0887 | router_z_loss: 0.0004 | router_aux_loss: 0.0007 | lr: 0.000308\n",
      "step 530  | loss: 1.0098 | lm_loss: 1.0087 | router_z_loss: 0.0004 | router_aux_loss: 0.0007 | lr: 0.000306\n",
      "step 540  | loss: 1.0514 | lm_loss: 1.0504 | router_z_loss: 0.0003 | router_aux_loss: 0.0007 | lr: 0.000304\n",
      "step 550  | loss: 1.0452 | lm_loss: 1.0441 | router_z_loss: 0.0003 | router_aux_loss: 0.0007 | lr: 0.000302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c60a61d9b34aa691d05e41eee96ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.0375\n",
      "step 560  | loss: 1.0334 | lm_loss: 1.0324 | router_z_loss: 0.0003 | router_aux_loss: 0.0007 | lr: 0.000300\n",
      "step 570  | loss: 0.9741 | lm_loss: 0.9731 | router_z_loss: 0.0003 | router_aux_loss: 0.0007 | lr: 0.000298\n",
      "step 580  | loss: 0.8857 | lm_loss: 0.8847 | router_z_loss: 0.0004 | router_aux_loss: 0.0007 | lr: 0.000296\n",
      "step 590  | loss: 0.8963 | lm_loss: 0.8954 | router_z_loss: 0.0003 | router_aux_loss: 0.0006 | lr: 0.000294\n",
      "step 600  | loss: 1.0102 | lm_loss: 1.0092 | router_z_loss: 0.0003 | router_aux_loss: 0.0006 | lr: 0.000292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560e36e9f3e24fd584064ab0007aff0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.9410\n",
      "step 610  | loss: 0.8983 | lm_loss: 0.8974 | router_z_loss: 0.0003 | router_aux_loss: 0.0006 | lr: 0.000290\n",
      "step 620  | loss: 0.9484 | lm_loss: 0.9475 | router_z_loss: 0.0003 | router_aux_loss: 0.0006 | lr: 0.000288\n",
      "step 630  | loss: 0.9542 | lm_loss: 0.9534 | router_z_loss: 0.0003 | router_aux_loss: 0.0006 | lr: 0.000286\n",
      "step 640  | loss: 0.8591 | lm_loss: 0.8583 | router_z_loss: 0.0002 | router_aux_loss: 0.0006 | lr: 0.000284\n",
      "step 650  | loss: 0.8702 | lm_loss: 0.8693 | router_z_loss: 0.0003 | router_aux_loss: 0.0006 | lr: 0.000282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5d18d8dbcc487e9548a665da096159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.8686\n",
      "step 660  | loss: 0.8906 | lm_loss: 0.8898 | router_z_loss: 0.0002 | router_aux_loss: 0.0006 | lr: 0.000280\n",
      "step 670  | loss: 0.7473 | lm_loss: 0.7465 | router_z_loss: 0.0002 | router_aux_loss: 0.0006 | lr: 0.000278\n",
      "step 680  | loss: 0.8081 | lm_loss: 0.8074 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000276\n",
      "step 690  | loss: 0.8927 | lm_loss: 0.8919 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000274\n",
      "step 700  | loss: 0.7832 | lm_loss: 0.7824 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457ed3140d7d4a80af0fca532d434093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.8411\n",
      "step 710  | loss: 0.8310 | lm_loss: 0.8303 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000270\n",
      "step 720  | loss: 0.8526 | lm_loss: 0.8519 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000268\n",
      "step 730  | loss: 0.7445 | lm_loss: 0.7439 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000266\n",
      "step 740  | loss: 0.8015 | lm_loss: 0.8009 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000265\n",
      "step 750  | loss: 0.7679 | lm_loss: 0.7672 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e83f92ec7940ee88026a5169d60505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.7626\n",
      "step 760  | loss: 0.7632 | lm_loss: 0.7625 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000261\n",
      "step 770  | loss: 0.8589 | lm_loss: 0.8583 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000259\n",
      "step 780  | loss: 0.7840 | lm_loss: 0.7833 | router_z_loss: 0.0002 | router_aux_loss: 0.0005 | lr: 0.000257\n",
      "step 790  | loss: 0.6988 | lm_loss: 0.6981 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000255\n",
      "step 800  | loss: 0.7631 | lm_loss: 0.7625 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2cf706cf344525bc9c6d97063adaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.7367\n",
      "step 810  | loss: 0.7945 | lm_loss: 0.7939 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000251\n",
      "step 820  | loss: 0.7315 | lm_loss: 0.7309 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000249\n",
      "step 830  | loss: 0.7177 | lm_loss: 0.7170 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000247\n",
      "step 840  | loss: 0.7881 | lm_loss: 0.7875 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000245\n",
      "step 850  | loss: 0.6879 | lm_loss: 0.6873 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e087d99da9a4597836b039a6b378cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.7112\n",
      "step 860  | loss: 0.6358 | lm_loss: 0.6352 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000241\n",
      "step 870  | loss: 0.6643 | lm_loss: 0.6637 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000239\n",
      "step 880  | loss: 0.7159 | lm_loss: 0.7153 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000237\n",
      "step 890  | loss: 0.6668 | lm_loss: 0.6663 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000235\n",
      "step 900  | loss: 0.7259 | lm_loss: 0.7254 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3031cca63846769f7060301978a510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.6755\n",
      "step 910  | loss: 0.6078 | lm_loss: 0.6072 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000231\n",
      "step 920  | loss: 0.7332 | lm_loss: 0.7328 | router_z_loss: 0.0002 | router_aux_loss: 0.0003 | lr: 0.000229\n",
      "step 930  | loss: 0.6398 | lm_loss: 0.6394 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000227\n",
      "step 940  | loss: 0.6681 | lm_loss: 0.6676 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000225\n",
      "step 950  | loss: 0.6065 | lm_loss: 0.6060 | router_z_loss: 0.0002 | router_aux_loss: 0.0003 | lr: 0.000223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c572c3d323634b9ba3845672062bcf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.6547\n",
      "step 960  | loss: 0.5821 | lm_loss: 0.5816 | router_z_loss: 0.0002 | router_aux_loss: 0.0003 | lr: 0.000221\n",
      "step 970  | loss: 0.6279 | lm_loss: 0.6274 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000219\n",
      "step 980  | loss: 0.5765 | lm_loss: 0.5761 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000217\n",
      "step 990  | loss: 0.5916 | lm_loss: 0.5911 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000215\n",
      "step 1000 | loss: 0.5391 | lm_loss: 0.5385 | router_z_loss: 0.0002 | router_aux_loss: 0.0004 | lr: 0.000213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786ae34439284eeaab08b26f80470abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.6166\n",
      "step 1010 | loss: 0.7458 | lm_loss: 0.7453 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000211\n",
      "step 1020 | loss: 0.6217 | lm_loss: 0.6212 | router_z_loss: 0.0002 | router_aux_loss: 0.0003 | lr: 0.000210\n",
      "step 1030 | loss: 0.6857 | lm_loss: 0.6852 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000208\n",
      "step 1040 | loss: 0.6114 | lm_loss: 0.6109 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000206\n",
      "step 1050 | loss: 0.6508 | lm_loss: 0.6504 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dedceaa7f342dea3b5ceb5479d4db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.6060\n",
      "step 1060 | loss: 0.6093 | lm_loss: 0.6089 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000202\n",
      "step 1070 | loss: 0.6084 | lm_loss: 0.6079 | router_z_loss: 0.0002 | router_aux_loss: 0.0003 | lr: 0.000200\n",
      "step 1080 | loss: 0.5897 | lm_loss: 0.5893 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000198\n",
      "step 1090 | loss: 0.5534 | lm_loss: 0.5530 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000196\n",
      "step 1100 | loss: 0.5950 | lm_loss: 0.5946 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18069e50a6d4aae9a6d5308c64e7470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5926\n",
      "step 1110 | loss: 0.6147 | lm_loss: 0.6142 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000192\n",
      "step 1120 | loss: 0.5588 | lm_loss: 0.5584 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000190\n",
      "step 1130 | loss: 0.5464 | lm_loss: 0.5460 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000188\n",
      "step 1140 | loss: 0.6081 | lm_loss: 0.6077 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000186\n",
      "step 1150 | loss: 0.5565 | lm_loss: 0.5561 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0491b927d60476c846efa95f1507626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5646\n",
      "step 1160 | loss: 0.6685 | lm_loss: 0.6681 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000182\n",
      "step 1170 | loss: 0.5713 | lm_loss: 0.5709 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000180\n",
      "step 1180 | loss: 0.5139 | lm_loss: 0.5135 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000178\n",
      "step 1190 | loss: 0.5018 | lm_loss: 0.5013 | router_z_loss: 0.0002 | router_aux_loss: 0.0003 | lr: 0.000176\n",
      "step 1200 | loss: 0.5785 | lm_loss: 0.5781 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194232cfe1914ba3abe611eecc2d4609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5634\n",
      "step 1210 | loss: 0.5025 | lm_loss: 0.5021 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000172\n",
      "step 1220 | loss: 0.5544 | lm_loss: 0.5540 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000170\n",
      "step 1230 | loss: 0.5392 | lm_loss: 0.5389 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000168\n",
      "step 1240 | loss: 0.5098 | lm_loss: 0.5095 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000166\n",
      "step 1250 | loss: 0.5462 | lm_loss: 0.5458 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a77d74a56e46c7bb7349c46403e721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5296\n",
      "step 1260 | loss: 0.5786 | lm_loss: 0.5782 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000162\n",
      "step 1270 | loss: 0.5145 | lm_loss: 0.5141 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000160\n",
      "step 1280 | loss: 0.4265 | lm_loss: 0.4262 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000158\n",
      "step 1290 | loss: 0.4655 | lm_loss: 0.4652 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000157\n",
      "step 1300 | loss: 0.5542 | lm_loss: 0.5538 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6c00ffb4ac4cf68fa1fba64a234e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5303\n",
      "step 1310 | loss: 0.4460 | lm_loss: 0.4457 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000153\n",
      "step 1320 | loss: 0.4598 | lm_loss: 0.4595 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000151\n",
      "step 1330 | loss: 0.5490 | lm_loss: 0.5487 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000149\n",
      "step 1340 | loss: 0.5337 | lm_loss: 0.5333 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000147\n",
      "step 1350 | loss: 0.5546 | lm_loss: 0.5542 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037d62469fff41a9bc688ed04d8b3519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5086\n",
      "step 1360 | loss: 0.4608 | lm_loss: 0.4604 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000143\n",
      "step 1370 | loss: 0.4373 | lm_loss: 0.4369 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000141\n",
      "step 1380 | loss: 0.4945 | lm_loss: 0.4942 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000139\n",
      "step 1390 | loss: 0.4415 | lm_loss: 0.4412 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000137\n",
      "step 1400 | loss: 0.5207 | lm_loss: 0.5204 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834f9b05821a4aff847312f60056528e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5101\n",
      "step 1410 | loss: 0.4903 | lm_loss: 0.4899 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000133\n",
      "step 1420 | loss: 0.3747 | lm_loss: 0.3743 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000131\n",
      "step 1430 | loss: 0.5029 | lm_loss: 0.5026 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000129\n",
      "step 1440 | loss: 0.5878 | lm_loss: 0.5875 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000127\n",
      "step 1450 | loss: 0.5326 | lm_loss: 0.5323 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f2afbea5734b1ba5bea3a466f0ac6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4885\n",
      "step 1460 | loss: 0.5024 | lm_loss: 0.5021 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000123\n",
      "step 1470 | loss: 0.4735 | lm_loss: 0.4732 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000121\n",
      "step 1480 | loss: 0.4241 | lm_loss: 0.4237 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000119\n",
      "step 1490 | loss: 0.5409 | lm_loss: 0.5406 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000117\n",
      "step 1500 | loss: 0.6167 | lm_loss: 0.6163 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dd37b357fb431f9b2b1da8c10e83bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4712\n",
      "step 1510 | loss: 0.5165 | lm_loss: 0.5162 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000113\n",
      "step 1520 | loss: 0.4622 | lm_loss: 0.4618 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000111\n",
      "step 1530 | loss: 0.4397 | lm_loss: 0.4394 | router_z_loss: 0.0001 | router_aux_loss: 0.0003 | lr: 0.000109\n",
      "step 1540 | loss: 0.4269 | lm_loss: 0.4266 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000107\n",
      "step 1550 | loss: 0.4106 | lm_loss: 0.4103 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e988ad1fc242999bf757fe3eefd848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4748\n",
      "step 1560 | loss: 0.4558 | lm_loss: 0.4555 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000103\n",
      "step 1570 | loss: 0.5932 | lm_loss: 0.5929 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000102\n",
      "step 1580 | loss: 0.5024 | lm_loss: 0.5020 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000100\n",
      "step 1590 | loss: 0.4417 | lm_loss: 0.4413 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000098\n",
      "step 1600 | loss: 0.5512 | lm_loss: 0.5508 | router_z_loss: 0.0001 | router_aux_loss: 0.0002 | lr: 0.000096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c445c46b772042bbb7e1bb8362924c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/git/BALM/balm/training/trainer.py:224\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# eval\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m completed_steps \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    222\u001b[0m ):\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# print(\"Evaluating\")\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(compute_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# save\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m completed_steps \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    230\u001b[0m ):\n",
      "File \u001b[0;32m~/git/BALM/balm/training/trainer.py:275\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, compute_metrics)\u001b[0m\n\u001b[1;32m    273\u001b[0m collated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_collator(batch)\n\u001b[1;32m    274\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_inputs(collated)\n\u001b[0;32m--> 275\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    276\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    277\u001b[0m     labels\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    278\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    279\u001b[0m     key_padding_mask\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_padding_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    281\u001b[0m tmp_eval_loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m    282\u001b[0m eval_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tmp_eval_loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/BALM/balm/models/balm_moe.py:370\u001b[0m, in \u001b[0;36mBalmMoEForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, key_padding_mask, labels, output_attentions, output_hidden_states, output_router_logits, output_expert_indexes, return_dict)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    input_ids (torch.LongTensor): tokenized input IDs\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    attention_mask (torch.BoolTensor): attention mask\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    return_dict (bool): return a dictionary of outputs\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# encoder\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbalm(\n\u001b[1;32m    371\u001b[0m     input_ids,\n\u001b[1;32m    372\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    373\u001b[0m     key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    374\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    375\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    376\u001b[0m     output_router_logits\u001b[38;5;241m=\u001b[39moutput_router_logits,\n\u001b[1;32m    377\u001b[0m     output_expert_indexes\u001b[38;5;241m=\u001b[39moutput_expert_indexes,\n\u001b[1;32m    378\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    379\u001b[0m )\n\u001b[1;32m    380\u001b[0m x \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_hidden_state\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    381\u001b[0m router_z_loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouter_z_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/BALM/balm/models/balm_moe.py:235\u001b[0m, in \u001b[0;36mBalmMoEModel.forward\u001b[0;34m(self, input_ids, attention_mask, key_padding_mask, output_attentions, output_hidden_states, output_router_logits, output_expert_indexes, return_dict)\u001b[0m\n\u001b[1;32m    232\u001b[0m         hidden_states[layer_idx] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# dense layer, no router info needed\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(\n\u001b[1;32m    236\u001b[0m         x,\n\u001b[1;32m    237\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    238\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    241\u001b[0m         x, attn \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/BALM/balm/modules.py:145\u001b[0m, in \u001b[0;36mTransformerLayer.forward\u001b[0;34m(self, x, attention_mask, key_padding_mask, need_weights)\u001b[0m\n\u001b[1;32m    142\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# attention\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    146\u001b[0m     x,\n\u001b[1;32m    147\u001b[0m     x,\n\u001b[1;32m    148\u001b[0m     x,\n\u001b[1;32m    149\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    150\u001b[0m     key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    151\u001b[0m     need_weights\u001b[38;5;241m=\u001b[39mneed_weights,\n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_weights:\n\u001b[1;32m    154\u001b[0m     x, weights \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:1196\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         merged_mask, mask_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_masks(attn_mask, key_padding_mask, query)\n\u001b[1;32m   1195\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1196\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_native_multi_head_attention(\n\u001b[1;32m   1197\u001b[0m                 query,\n\u001b[1;32m   1198\u001b[0m                 key,\n\u001b[1;32m   1199\u001b[0m                 value,\n\u001b[1;32m   1200\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim,\n\u001b[1;32m   1201\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1202\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight,\n\u001b[1;32m   1203\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   1204\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   1205\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1206\u001b[0m                 merged_mask,\n\u001b[1;32m   1207\u001b[0m                 need_weights,\n\u001b[1;32m   1208\u001b[0m                 average_attn_weights,\n\u001b[1;32m   1209\u001b[0m                 mask_type)\n\u001b[1;32m   1211\u001b[0m any_nested \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mis_nested \u001b[38;5;129;01mor\u001b[39;00m key\u001b[38;5;241m.\u001b[39mis_nested \u001b[38;5;129;01mor\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_nested\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m any_nested, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiheadAttention does not support NestedTensor outside of its fast path. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   1213\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe fast path was not hit because \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhy_not_fast_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
