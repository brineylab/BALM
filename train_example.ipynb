{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from balm.config import BalmConfig\n",
    "from balm.data import load_dataset, DataCollator\n",
    "from balm.models import (\n",
    "    BalmForMaskedLM,\n",
    "    BalmMoEForMaskedLM,\n",
    "    BalmExpertChoiceMoEForMaskedLM,\n",
    "    BalmHybridMoEForMaskedLM,\n",
    ")\n",
    "from balm.tokenizer import Tokenizer\n",
    "from balm.train import Trainer\n",
    "\n",
    "import json\n",
    "\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=\"./vocab.json\")\n",
    "# tokenizer = EsmTokenizer.from_pretrained(\"./vocab.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sep(txt):\n",
    "    return txt.replace(\"</s>\", \"<cls><cls>\")\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"test\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"eval\": \"./balm/test_data/test_1k.txt\",\n",
    "}\n",
    "\n",
    "# data_files = {\n",
    "#     \"train\": \"../train-test-eval_paired/train.txt\",\n",
    "#     \"test\": \"../train-test-eval_paired/test.txt\",\n",
    "#     \"eval\": \"../train-test-eval_paired/eval.txt\",\n",
    "# }\n",
    "\n",
    "# data_files = {\n",
    "#     \"train\": \"~/shared/Sarah/training-data/paired-longitudinalHD/data/clust90-split/jaffe_longHD_clust90_train.csv\",\n",
    "#     \"test\": \"~/shared/Sarah/training-data/paired-longitudinalHD/data/clust90-split/jaffe_longHD_clust90_test.csv\",\n",
    "#     \"eval\": \"~/shared/Sarah/training-data/paired-longitudinalHD/data/clust90-split/jaffe_longHD_clust90_eval.csv\",\n",
    "# }\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=data_files, preprocess_fn=remove_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd447c358286426dad46ec81b7e40567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfdeaf824e940519b86828fae980cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fca1680351343ae838486abd8f7087f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        x[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=320,\n",
    "    ),\n",
    "    remove_columns=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollator(tokenizer=tokenizer)\n",
    "# collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer, \n",
    "#     mlm=True,\n",
    "#     mlm_probability=0.15,\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched to ESM-2 8M\n",
    "config = BalmConfig(\n",
    "    embed_dim=320,\n",
    "    ffn_dim=320*4,\n",
    "    num_layers=6,\n",
    "    num_heads=20,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "# model = BalmForMaskedLM(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320*4,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "model = BalmForMaskedLM(config=config)\n",
    "\n",
    "# # matched to ESM-2 8M\n",
    "# model = BalmMoEForMaskedLM(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320*4,\n",
    "#     num_experts=8,\n",
    "#     num_shared_experts=0,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     alternate_sparsity=True,\n",
    "#     router_top_k=1,\n",
    "#     expert_capacity=128,\n",
    "#     router_z_loss_coef=0.01,\n",
    "#     router_aux_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "\n",
    "# # matched to ESM-2 8M\n",
    "# model = BalmExpertChoiceMoEForMaskedLM(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320 * 4,\n",
    "#     num_experts=8,\n",
    "#     num_shared_experts=0,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     alternate_sparsity=False,\n",
    "#     expert_capacity=128,\n",
    "#     router_z_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6294113"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"eval\"],\n",
    "    output_dir=\"./training_runs/save_tests\",\n",
    "    epochs=1,\n",
    "    logging_steps=5,\n",
    "    eval_steps=10,\n",
    "    warmup_steps=10,\n",
    "    save_steps=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    # use_cpu=True,\n",
    "    # use_wandb=True,\n",
    "    wandb_project=\"test_wandb_logging\",\n",
    "    # wandb_entity=\"bryanbriney\",\n",
    "    run_name=\"save_test_001\",\n",
    ")\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"~/Desktop/training\",\n",
    "#     logging_dir=\"~/Desktop/training/log\",\n",
    "#     per_device_train_batch_size=32,\n",
    "#     learning_rate=1e-4,\n",
    "#     max_steps=2000,\n",
    "#     gradient_accumulation_steps=1,\n",
    "#     logging_steps=10,\n",
    "#     eval_steps=50,\n",
    "#     warmup_steps=100,\n",
    "#     use_cpu=True,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=collator,\n",
    "#     train_dataset=tokenized_dataset[\"train\"],\n",
    "#     eval_dataset=tokenized_dataset[\"eval\"],\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bryanbriney/git/BALM/training_runs/save_tests'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbryanbriney\u001b[0m (\u001b[33mthebrineylab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_PROJECT\"] = trainer.run_name\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a101aaee6bd446a9efebc5bf2a55b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5     | loss: 3.1558 | lr: 0.000200\n",
      "step 10    | loss: 2.8548 | lr: 0.000400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e32dc33c574a02b649df191c3e9a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< EVAL >> | loss: 2.8366 | accuracy: 0.2139 | perplexity: 15.6163\n",
      "step 15    | loss: 2.6944 | lr: 0.000305\n",
      "<< SAVING MODEL CHECKPOINT >>\n",
      "step 20    | loss: 2.7200 | lr: 0.000210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8324e69206e44fbb3149d98add662c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< EVAL >> | loss: 2.7276 | accuracy: 0.2231 | perplexity: 14.0248\n",
      "step 25    | loss: 2.6147 | lr: 0.000114\n",
      "step 30    | loss: 2.6676 | lr: 0.000019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9daa488c30e742b8bfeb6b2906cd698c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< EVAL >> | loss: 2.7190 | accuracy: 0.2226 | perplexity: 13.9186\n",
      "<< SAVING MODEL CHECKPOINT >>\n",
      "<< SAVING FINAL MODEL >>\n",
      "\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
