{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from balm.data import load_dataset, DataCollator\n",
    "from balm.models import (\n",
    "    BalmForMaskedLM,\n",
    "    BalmMoEForMaskedLM,\n",
    "    BalmExpertChoiceMoEForMaskedLM,\n",
    "    BalmHybridMoEForMaskedLM,\n",
    ")\n",
    "from balm.tokenizer import Tokenizer\n",
    "from balm.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=\"./vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sep(txt):\n",
    "    return txt.replace(\"</s>\", \"<cls><cls>\")\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"./balm/test_data/test.txt\",\n",
    "    \"test\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"eval\": \"./balm/test_data/test_1k.txt\",\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=data_files, preprocess_fn=remove_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        x[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=320,\n",
    "    ),\n",
    "    remove_columns=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched to ESM-2 8M\n",
    "model = BalmForMaskedLM(\n",
    "    embed_dim=320,\n",
    "    ffn_dim=320*4,\n",
    "    num_layers=6,\n",
    "    num_heads=20,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "\n",
    "# # matched to ESM-2 8M\n",
    "# model = BalmMoEForMaskedLM(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320*4,\n",
    "#     num_experts=8,\n",
    "#     num_shared_experts=0,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     alternate_sparsity=True,\n",
    "#     router_top_k=1,\n",
    "#     expert_capacity=128,\n",
    "#     router_z_loss_coef=0.01,\n",
    "#     router_aux_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "\n",
    "# # matched to ESM-2 8M\n",
    "# model = BalmExpertChoiceMoEForMaskedLM(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320 * 4,\n",
    "#     num_experts=8,\n",
    "#     num_shared_experts=0,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     alternate_sparsity=False,\n",
    "#     expert_capacity=128,\n",
    "#     router_z_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6294113"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"eval\"],\n",
    "    epochs=1,\n",
    "    logging_steps=10,\n",
    "    eval_steps=50,\n",
    "    warmup_steps=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    # use_cpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2474549b00f74a22aaaa1ce5f45dc517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2087 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10   | loss: 3.1020 | lr: 0.000080\n",
      "step 20   | loss: 2.7443 | lr: 0.000160\n",
      "step 30   | loss: 2.6527 | lr: 0.000240\n",
      "step 40   | loss: 2.6453 | lr: 0.000320\n",
      "step 50   | loss: 2.5886 | lr: 0.000400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b605dddee28469f8f7e1feb34055956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 2.6825\n",
      "step 60   | loss: 2.5415 | lr: 0.000398\n",
      "step 70   | loss: 2.2838 | lr: 0.000396\n",
      "step 80   | loss: 2.2063 | lr: 0.000394\n",
      "step 90   | loss: 2.1203 | lr: 0.000392\n",
      "step 100  | loss: 2.1287 | lr: 0.000390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c19ca3583041a484864bbd3ad781b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 2.1314\n",
      "step 110  | loss: 1.9825 | lr: 0.000388\n",
      "step 120  | loss: 1.9320 | lr: 0.000386\n",
      "step 130  | loss: 1.9641 | lr: 0.000384\n",
      "step 140  | loss: 1.9640 | lr: 0.000382\n",
      "step 150  | loss: 1.8985 | lr: 0.000380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9ec2c7fa8848d598a0a990d1d82933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.9031\n",
      "step 160  | loss: 1.8407 | lr: 0.000378\n",
      "step 170  | loss: 1.7660 | lr: 0.000376\n",
      "step 180  | loss: 1.6834 | lr: 0.000374\n",
      "step 190  | loss: 1.6126 | lr: 0.000373\n",
      "step 200  | loss: 1.6124 | lr: 0.000371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ab1eea537f4b02842e2d0cd55312be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.6210\n",
      "step 210  | loss: 1.5491 | lr: 0.000369\n",
      "step 220  | loss: 1.5128 | lr: 0.000367\n",
      "step 230  | loss: 1.4577 | lr: 0.000365\n",
      "step 240  | loss: 1.4858 | lr: 0.000363\n",
      "step 250  | loss: 1.4321 | lr: 0.000361\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a956037b943449b921530c9102ce807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.4053\n",
      "step 260  | loss: 1.3326 | lr: 0.000359\n",
      "step 270  | loss: 1.4082 | lr: 0.000357\n",
      "step 280  | loss: 1.2744 | lr: 0.000355\n",
      "step 290  | loss: 1.2189 | lr: 0.000353\n",
      "step 300  | loss: 1.1393 | lr: 0.000351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b09427f0fc44551b3776703eb757081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.2633\n",
      "step 310  | loss: 1.1223 | lr: 0.000349\n",
      "step 320  | loss: 1.2093 | lr: 0.000347\n",
      "step 330  | loss: 1.2347 | lr: 0.000345\n",
      "step 340  | loss: 1.1423 | lr: 0.000343\n",
      "step 350  | loss: 1.1128 | lr: 0.000341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4780286fa4f41ddac06fd2cd133412d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 1.1003\n",
      "step 360  | loss: 1.0664 | lr: 0.000339\n",
      "step 370  | loss: 1.0037 | lr: 0.000337\n",
      "step 380  | loss: 1.0089 | lr: 0.000335\n",
      "step 390  | loss: 1.0358 | lr: 0.000333\n",
      "step 400  | loss: 0.9334 | lr: 0.000331\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dabaa3f68f04825833099be81587cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.9782\n",
      "step 410  | loss: 0.9920 | lr: 0.000329\n",
      "step 420  | loss: 0.8711 | lr: 0.000327\n",
      "step 430  | loss: 0.9032 | lr: 0.000325\n",
      "step 440  | loss: 0.8752 | lr: 0.000323\n",
      "step 450  | loss: 0.9360 | lr: 0.000321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78fd1a4bed44feb831b25ba4d802588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.8778\n",
      "step 460  | loss: 0.8293 | lr: 0.000319\n",
      "step 470  | loss: 0.9083 | lr: 0.000318\n",
      "step 480  | loss: 0.8401 | lr: 0.000316\n",
      "step 490  | loss: 0.8241 | lr: 0.000314\n",
      "step 500  | loss: 0.7942 | lr: 0.000312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe2a1cdda8d4d1eaeb749087218e69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.8291\n",
      "step 510  | loss: 0.8690 | lr: 0.000310\n",
      "step 520  | loss: 0.7452 | lr: 0.000308\n",
      "step 530  | loss: 0.7309 | lr: 0.000306\n",
      "step 540  | loss: 0.6372 | lr: 0.000304\n",
      "step 550  | loss: 0.7340 | lr: 0.000302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e2ed3736b649329df093d80ba0e0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.7571\n",
      "step 560  | loss: 0.7693 | lr: 0.000300\n",
      "step 570  | loss: 0.6750 | lr: 0.000298\n",
      "step 580  | loss: 0.6693 | lr: 0.000296\n",
      "step 590  | loss: 0.6618 | lr: 0.000294\n",
      "step 600  | loss: 0.6492 | lr: 0.000292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3331ed110f496ea8a61b965a02c968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.7068\n",
      "step 610  | loss: 0.6381 | lr: 0.000290\n",
      "step 620  | loss: 0.7049 | lr: 0.000288\n",
      "step 630  | loss: 0.7305 | lr: 0.000286\n",
      "step 640  | loss: 0.6417 | lr: 0.000284\n",
      "step 650  | loss: 0.6464 | lr: 0.000282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de99ff68f5a74f1c8f5d485448e32f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.6615\n",
      "step 660  | loss: 0.6438 | lr: 0.000280\n",
      "step 670  | loss: 0.5524 | lr: 0.000278\n",
      "step 680  | loss: 0.5674 | lr: 0.000276\n",
      "step 690  | loss: 0.6030 | lr: 0.000274\n",
      "step 700  | loss: 0.6130 | lr: 0.000272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe33c71e89d4be58915a34265adaeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.6271\n",
      "step 710  | loss: 0.5672 | lr: 0.000270\n",
      "step 720  | loss: 0.6053 | lr: 0.000268\n",
      "step 730  | loss: 0.5970 | lr: 0.000266\n",
      "step 740  | loss: 0.5577 | lr: 0.000265\n",
      "step 750  | loss: 0.5638 | lr: 0.000263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093ec80fc58f4696a7823221e4fcfdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.6003\n",
      "step 760  | loss: 0.5937 | lr: 0.000261\n",
      "step 770  | loss: 0.6897 | lr: 0.000259\n",
      "step 780  | loss: 0.5801 | lr: 0.000257\n",
      "step 790  | loss: 0.4468 | lr: 0.000255\n",
      "step 800  | loss: 0.5985 | lr: 0.000253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d43f7067804260bdba2d6566bd0820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5756\n",
      "step 810  | loss: 0.5855 | lr: 0.000251\n",
      "step 820  | loss: 0.6151 | lr: 0.000249\n",
      "step 830  | loss: 0.5341 | lr: 0.000247\n",
      "step 840  | loss: 0.5753 | lr: 0.000245\n",
      "step 850  | loss: 0.5145 | lr: 0.000243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117764155d8d4742820caed5800dfe87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5505\n",
      "step 860  | loss: 0.5101 | lr: 0.000241\n",
      "step 870  | loss: 0.5521 | lr: 0.000239\n",
      "step 880  | loss: 0.5879 | lr: 0.000237\n",
      "step 890  | loss: 0.5239 | lr: 0.000235\n",
      "step 900  | loss: 0.5155 | lr: 0.000233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cdb0677e644cd98e67b0371f8d3298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5304\n",
      "step 910  | loss: 0.4332 | lr: 0.000231\n",
      "step 920  | loss: 0.5433 | lr: 0.000229\n",
      "step 930  | loss: 0.5131 | lr: 0.000227\n",
      "step 940  | loss: 0.5850 | lr: 0.000225\n",
      "step 950  | loss: 0.5835 | lr: 0.000223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec12ed1687b446398a04868cfa87275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5268\n",
      "step 960  | loss: 0.4257 | lr: 0.000221\n",
      "step 970  | loss: 0.5519 | lr: 0.000219\n",
      "step 980  | loss: 0.4773 | lr: 0.000217\n",
      "step 990  | loss: 0.4797 | lr: 0.000215\n",
      "step 1000 | loss: 0.4934 | lr: 0.000213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dccdf5511e4f568cb9c6207cd665df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5149\n",
      "step 1010 | loss: 0.6018 | lr: 0.000211\n",
      "step 1020 | loss: 0.5279 | lr: 0.000210\n",
      "step 1030 | loss: 0.5409 | lr: 0.000208\n",
      "step 1040 | loss: 0.4465 | lr: 0.000206\n",
      "step 1050 | loss: 0.5558 | lr: 0.000204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71954a0fada849828e486577b38533c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4867\n",
      "step 1060 | loss: 0.4211 | lr: 0.000202\n",
      "step 1070 | loss: 0.4368 | lr: 0.000200\n",
      "step 1080 | loss: 0.5023 | lr: 0.000198\n",
      "step 1090 | loss: 0.4219 | lr: 0.000196\n",
      "step 1100 | loss: 0.5235 | lr: 0.000194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e84968ea1048949cea8b72528da162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.5042\n",
      "step 1110 | loss: 0.4913 | lr: 0.000192\n",
      "step 1120 | loss: 0.4468 | lr: 0.000190\n",
      "step 1130 | loss: 0.4980 | lr: 0.000188\n",
      "step 1140 | loss: 0.6059 | lr: 0.000186\n",
      "step 1150 | loss: 0.4300 | lr: 0.000184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f27b6fa6694e499365e7d3873f9dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4681\n",
      "step 1160 | loss: 0.6297 | lr: 0.000182\n",
      "step 1170 | loss: 0.5152 | lr: 0.000180\n",
      "step 1180 | loss: 0.3479 | lr: 0.000178\n",
      "step 1190 | loss: 0.4011 | lr: 0.000176\n",
      "step 1200 | loss: 0.4574 | lr: 0.000174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f08753b8504aad935b707faf5426fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4680\n",
      "step 1210 | loss: 0.3992 | lr: 0.000172\n",
      "step 1220 | loss: 0.4974 | lr: 0.000170\n",
      "step 1230 | loss: 0.5163 | lr: 0.000168\n",
      "step 1240 | loss: 0.3897 | lr: 0.000166\n",
      "step 1250 | loss: 0.5078 | lr: 0.000164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934a15684eea4e2ead7d3044653ee7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4421\n",
      "step 1260 | loss: 0.4292 | lr: 0.000162\n",
      "step 1270 | loss: 0.4816 | lr: 0.000160\n",
      "step 1280 | loss: 0.3368 | lr: 0.000158\n",
      "step 1290 | loss: 0.3588 | lr: 0.000157\n",
      "step 1300 | loss: 0.4232 | lr: 0.000155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee8bbacb0aa4f3db342dc1913d21c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4475\n",
      "step 1310 | loss: 0.4150 | lr: 0.000153\n",
      "step 1320 | loss: 0.3775 | lr: 0.000151\n",
      "step 1330 | loss: 0.4169 | lr: 0.000149\n",
      "step 1340 | loss: 0.5353 | lr: 0.000147\n",
      "step 1350 | loss: 0.3301 | lr: 0.000145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c19785e902c4c4f81963cf2ea321346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4350\n",
      "step 1360 | loss: 0.4034 | lr: 0.000143\n",
      "step 1370 | loss: 0.3313 | lr: 0.000141\n",
      "step 1380 | loss: 0.4552 | lr: 0.000139\n",
      "step 1390 | loss: 0.4441 | lr: 0.000137\n",
      "step 1400 | loss: 0.4393 | lr: 0.000135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6422705f2d48b793888730db8b1276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4329\n",
      "step 1410 | loss: 0.4099 | lr: 0.000133\n",
      "step 1420 | loss: 0.3280 | lr: 0.000131\n",
      "step 1430 | loss: 0.4643 | lr: 0.000129\n",
      "step 1440 | loss: 0.4185 | lr: 0.000127\n",
      "step 1450 | loss: 0.4268 | lr: 0.000125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18705ab244f1415496c5d009c9746044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4182\n",
      "step 1460 | loss: 0.3901 | lr: 0.000123\n",
      "step 1470 | loss: 0.3078 | lr: 0.000121\n",
      "step 1480 | loss: 0.3784 | lr: 0.000119\n",
      "step 1490 | loss: 0.5291 | lr: 0.000117\n",
      "step 1500 | loss: 0.4727 | lr: 0.000115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b177be4bab6642c089d7a885051813e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4229\n",
      "step 1510 | loss: 0.5057 | lr: 0.000113\n",
      "step 1520 | loss: 0.3756 | lr: 0.000111\n",
      "step 1530 | loss: 0.3378 | lr: 0.000109\n",
      "step 1540 | loss: 0.4084 | lr: 0.000107\n",
      "step 1550 | loss: 0.4142 | lr: 0.000105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d12c43785743c09a9bac7b62700ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4152\n",
      "step 1560 | loss: 0.4156 | lr: 0.000103\n",
      "step 1570 | loss: 0.5196 | lr: 0.000102\n",
      "step 1580 | loss: 0.4002 | lr: 0.000100\n",
      "step 1590 | loss: 0.3420 | lr: 0.000098\n",
      "step 1600 | loss: 0.3743 | lr: 0.000096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e21184e4c684b8290e9fdd0b95e9f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4134\n",
      "step 1610 | loss: 0.4204 | lr: 0.000094\n",
      "step 1620 | loss: 0.3372 | lr: 0.000092\n",
      "step 1630 | loss: 0.2907 | lr: 0.000090\n",
      "step 1640 | loss: 0.3942 | lr: 0.000088\n",
      "step 1650 | loss: 0.3021 | lr: 0.000086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a217acc2fc442eca9c7becb7f927952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.3983\n",
      "step 1660 | loss: 0.4938 | lr: 0.000084\n",
      "step 1670 | loss: 0.4348 | lr: 0.000082\n",
      "step 1680 | loss: 0.3812 | lr: 0.000080\n",
      "step 1690 | loss: 0.3805 | lr: 0.000078\n",
      "step 1700 | loss: 0.3646 | lr: 0.000076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fda331c53f14002950d318ec9c5f0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.3968\n",
      "step 1710 | loss: 0.3181 | lr: 0.000074\n",
      "step 1720 | loss: 0.3736 | lr: 0.000072\n",
      "step 1730 | loss: 0.4564 | lr: 0.000070\n",
      "step 1740 | loss: 0.4923 | lr: 0.000068\n",
      "step 1750 | loss: 0.3680 | lr: 0.000066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fb2d8dab424e21ae03cd04060254ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.4009\n",
      "step 1760 | loss: 0.3021 | lr: 0.000064\n",
      "step 1770 | loss: 0.3456 | lr: 0.000062\n",
      "step 1780 | loss: 0.3505 | lr: 0.000060\n",
      "step 1790 | loss: 0.4145 | lr: 0.000058\n",
      "step 1800 | loss: 0.3243 | lr: 0.000056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8adf00e69c94f3db4d2660d711abc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< EVAL >>> loss: 0.3980\n",
      "step 1810 | loss: 0.3906 | lr: 0.000054\n",
      "step 1820 | loss: 0.3631 | lr: 0.000052\n",
      "step 1830 | loss: 0.3979 | lr: 0.000050\n",
      "step 1840 | loss: 0.3852 | lr: 0.000049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/git/BALM/balm/train/trainer.py:195\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m collated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_collator(batch)\n\u001b[1;32m    194\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_inputs(collated)\n\u001b[0;32m--> 195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    196\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    197\u001b[0m     labels\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    198\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    199\u001b[0m     key_padding_mask\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_padding_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    201\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    202\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/BALM/balm/models/balm.py:238\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input_ids, labels, attention_mask, key_padding_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    216\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     return_dict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    223\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MaskedLMOutput:\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m        The output tensor. The shape is (batch_size, seq_len, vocab_size).\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbalm(\n\u001b[1;32m    237\u001b[0m         input_ids,\n\u001b[0;32m--> 238\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    239\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    240\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    243\u001b[0m         x, attn \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/BALM/balm/models/balm.py:129\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, attention_mask, key_padding_mask, need_weights)\u001b[0m\n\u001b[1;32m    125\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(x)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    127\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(\n\u001b[1;32m    128\u001b[0m         x,\n\u001b[0;32m--> 129\u001b[0m         x,\n\u001b[1;32m    130\u001b[0m         x,\n\u001b[1;32m    131\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    132\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    133\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39mneed_weights,\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m need_weights:\n\u001b[1;32m    136\u001b[0m         x, attn \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/BALM/balm/modules.py:244\u001b[0m, in \u001b[0;36mRoformerLayer.forward\u001b[0;34m(self, query, key, value, attention_mask, key_padding_mask, need_weights)\u001b[0m\n\u001b[1;32m    241\u001b[0m value_rot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_embedding(value_norm)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# attention\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    245\u001b[0m     query_rot,\n\u001b[1;32m    246\u001b[0m     key_rot,\n\u001b[1;32m    247\u001b[0m     value_rot,\n\u001b[1;32m    248\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    249\u001b[0m     key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    250\u001b[0m     need_weights\u001b[38;5;241m=\u001b[39mneed_weights,\n\u001b[1;32m    251\u001b[0m )\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_weights:\n\u001b[1;32m    253\u001b[0m     x, weights \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1242\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_zero_attn,\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1246\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m   1247\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m   1248\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39mneed_weights,\n\u001b[1;32m   1249\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m   1250\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1251\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/functional.py:5300\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   5299\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 5300\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)\n\u001b[1;32m   5301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5302\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/conda/lib/python3.11/site-packages/torch/nn/functional.py:4846\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4845\u001b[0m     b_q, b_k, b_v \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m-> 4846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
