{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from balm.config import BalmConfig, BalmMoEConfig, BalmExpertChoiceMoEConfig\n",
    "from balm.data import load_dataset, DataCollator\n",
    "from balm.models import (\n",
    "    BalmForMaskedLM,\n",
    "    BalmModel,\n",
    "    BalmMoEForMaskedLM,\n",
    "    BalmExpertChoiceMoEForMaskedLM,\n",
    "    BalmHybridMoEForMaskedLM,\n",
    "    BalmMoERoPEForMaskedLM,\n",
    ")\n",
    "from balm.tokenizer import Tokenizer\n",
    "from balm.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=\"./vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sep(txt):\n",
    "    return txt.replace(\"</s>\", \"<cls><cls>\")\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"test\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"eval\": \"./balm/test_data/test_1k.txt\",\n",
    "}\n",
    "\n",
    "# data_files = {\n",
    "#     \"train\": \"../train-test-eval_paired/train.txt\",\n",
    "#     \"test\": \"../train-test-eval_paired/test.txt\",\n",
    "#     \"eval\": \"../train-test-eval_paired/eval.txt\",\n",
    "# }\n",
    "\n",
    "# data_files = {\n",
    "#     \"train\": \"../jaffe-plusHD_clust0.9_split/train.txt\",\n",
    "#     \"test\": \"../jaffe-plusHD_clust0.9_split/test.txt\",\n",
    "#     \"eval\": \"../jaffe-plusHD_clust0.9_split/eval.txt\",\n",
    "# }\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=data_files, preprocess_fn=remove_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc12d8048d9a4785b1b0c1515bb84eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bea59f365624016b7c35d74a257bcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e42e51df4474c6ab38579e6c47d77c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        x[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=320,\n",
    "    ),\n",
    "    remove_columns=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # matched to ESM-2 8M\n",
    "# config = BalmConfig(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320 * 4,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "# # model = BalmForMaskedLM(\n",
    "# #     embed_dim=320,\n",
    "# #     ffn_dim=320*4,\n",
    "# #     num_layers=6,\n",
    "# #     num_heads=20,\n",
    "# #     vocab_size=tokenizer.vocab_size,\n",
    "# # )\n",
    "# model = BalmForMaskedLM(config=config)\n",
    "\n",
    "\n",
    "# # matched to ESM-2 8M\n",
    "# config = BalmMoEConfig(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320*4,\n",
    "#     num_experts=8,\n",
    "#     num_shared_experts=0,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     alternate_sparsity=True,\n",
    "#     router_top_k=1,\n",
    "#     router_z_loss_coef=0.01,\n",
    "#     router_aux_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "# # model = BalmMoEForMaskedLM(\n",
    "# #     embed_dim=320,\n",
    "# #     ffn_dim=320*4,\n",
    "# #     num_experts=16,\n",
    "# #     num_shared_experts=0,\n",
    "# #     num_layers=6,\n",
    "# #     num_heads=20,\n",
    "# #     alternate_sparsity=True,\n",
    "# #     router_top_k=1,\n",
    "# #     expert_capacity=128,\n",
    "# #     router_z_loss_coef=0.01,\n",
    "# #     router_aux_loss_coef=0.01,\n",
    "# #     vocab_size=tokenizer.vocab_size,\n",
    "# # )\n",
    "# model = BalmMoEForMaskedLM(config=config)\n",
    "\n",
    "\n",
    "# # matched to ESM-2 8M\n",
    "# config = BalmExpertChoiceMoEConfig(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320 * 4,\n",
    "#     num_experts=16,\n",
    "#     num_shared_experts=2,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     # alternate_sparsity=True,\n",
    "#     # router_top_k=1,\n",
    "#     # router_z_loss_coef=0.01,\n",
    "#     # router_aux_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "# # model = BalmExpertChoiceMoEForMaskedLM(\n",
    "# #     embed_dim=320,\n",
    "# #     ffn_dim=320 * 4,\n",
    "# #     num_experts=8,\n",
    "# #     num_shared_experts=0,\n",
    "# #     num_layers=6,\n",
    "# #     num_heads=20,\n",
    "# #     alternate_sparsity=False,\n",
    "# #     expert_capacity=128,\n",
    "# #     router_z_loss_coef=0.01,\n",
    "# #     vocab_size=tokenizer.vocab_size,\n",
    "# # )\n",
    "# model = BalmExpertChoiceMoEForMaskedLM(config=config)\n",
    "\n",
    "\n",
    "# matched to ESM-2 8M\n",
    "# config = BalmMoERopeConfig(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320*4,\n",
    "#     num_experts=8,\n",
    "#     num_shared_experts=0,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     alternate_sparsity=True,\n",
    "#     router_top_k=1,\n",
    "#     router_z_loss_coef=0.01,\n",
    "#     router_aux_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "model = BalmMoERoPEForMaskedLM(\n",
    "    embed_dim=320,\n",
    "    ffn_dim=320*4,\n",
    "    num_experts=4,\n",
    "    # num_shared_experts=0,\n",
    "    num_layers=6,\n",
    "    num_heads=20,\n",
    "    # alternate_sparsity=True,\n",
    "    # router_top_k=1,\n",
    "    expert_capacity=1.25*320/16,\n",
    "    expert_activation=\"swiglu\",\n",
    "    router_z_loss_coef=0.01,\n",
    "    router_aux_loss_coef=0.01,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "# model = BalmMoEForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17351393"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"eval\"],\n",
    "    output_dir=\"./training_runs/save_tests\",\n",
    "    epochs=1,\n",
    "    logging_steps=5,\n",
    "    eval_steps=100,\n",
    "    warmup_steps=10,\n",
    "    # save_steps=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    # use_cpu=True,\n",
    "    # use_wandb=True,\n",
    "    wandb_project=\"test_wandb_logging\",\n",
    "    # wandb_entity=\"bryanbriney\",\n",
    "    run_name=\"save_test_001\",\n",
    ")\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"~/Desktop/training\",\n",
    "#     logging_dir=\"~/Desktop/training/log\",\n",
    "#     per_device_train_batch_size=32,\n",
    "#     learning_rate=1e-4,\n",
    "#     max_steps=2000,\n",
    "#     gradient_accumulation_steps=1,\n",
    "#     logging_steps=10,\n",
    "#     eval_steps=50,\n",
    "#     warmup_steps=100,\n",
    "#     use_cpu=True,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=collator,\n",
    "#     train_dataset=tokenized_dataset[\"train\"],\n",
    "#     eval_dataset=tokenized_dataset[\"eval\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc05c438fd84d7aa42a8239dd164c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5     | loss: 3.3496 | lr: 0.000200\n",
      "step 10    | loss: 2.8190 | lr: 0.000400\n",
      "step 15    | loss: 2.7347 | lr: 0.000305\n",
      "step 20    | loss: 2.6890 | lr: 0.000210\n",
      "step 25    | loss: 2.6384 | lr: 0.000114\n",
      "step 30    | loss: 2.6233 | lr: 0.000019\n",
      "<< SAVING FINAL MODEL >>\n",
      "\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
