{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from balm.config import BalmConfig\n",
    "from balm.data import load_dataset, DataCollator\n",
    "from balm.models import (\n",
    "    BalmForMaskedLM,\n",
    "    BalmMoEForMaskedLM,\n",
    "    BalmExpertChoiceMoEForMaskedLM,\n",
    "    BalmHybridMoEForMaskedLM,\n",
    ")\n",
    "from balm.tokenizer import Tokenizer\n",
    "from balm.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=\"./vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sep(txt):\n",
    "    return txt.replace(\"</s>\", \"<cls><cls>\")\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"test\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"eval\": \"./balm/test_data/test_1k.txt\",\n",
    "}\n",
    "\n",
    "# data_files = {\n",
    "#     \"train\": \"../train-test-eval_paired/train.txt\",\n",
    "#     \"test\": \"../train-test-eval_paired/test.txt\",\n",
    "#     \"eval\": \"../train-test-eval_paired/eval.txt\",\n",
    "# }\n",
    "\n",
    "# data_files = {\n",
    "#     \"train\": \"../jaffe-plusHD_clust0.9_split/train.txt\",\n",
    "#     \"test\": \"../jaffe-plusHD_clust0.9_split/test.txt\",\n",
    "#     \"eval\": \"../jaffe-plusHD_clust0.9_split/eval.txt\",\n",
    "# }\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=data_files, preprocess_fn=remove_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236c8998ffae448790d1870cf81fa9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fafa29040514d2f9607ff68f692ef1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99a85d4fb7b47b3baa696921144eb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        x[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=320,\n",
    "    ),\n",
    "    remove_columns=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched to ESM-2 8M\n",
    "config = BalmConfig(\n",
    "    embed_dim=320,\n",
    "    ffn_dim=320*4,\n",
    "    num_layers=6,\n",
    "    num_heads=20,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "# model = BalmForMaskedLM(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320*4,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "model = BalmForMaskedLM(config=config)\n",
    "\n",
    "# # matched to ESM-2 8M\n",
    "# model = BalmMoEForMaskedLM(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320*4,\n",
    "#     num_experts=8,\n",
    "#     num_shared_experts=0,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     alternate_sparsity=True,\n",
    "#     router_top_k=1,\n",
    "#     expert_capacity=128,\n",
    "#     router_z_loss_coef=0.01,\n",
    "#     router_aux_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )\n",
    "\n",
    "# # matched to ESM-2 8M\n",
    "# model = BalmExpertChoiceMoEForMaskedLM(\n",
    "#     embed_dim=320,\n",
    "#     ffn_dim=320 * 4,\n",
    "#     num_experts=8,\n",
    "#     num_shared_experts=0,\n",
    "#     num_layers=6,\n",
    "#     num_heads=20,\n",
    "#     alternate_sparsity=False,\n",
    "#     expert_capacity=128,\n",
    "#     router_z_loss_coef=0.01,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6294113"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"eval\"],\n",
    "    output_dir=\"./training_runs/save_tests\",\n",
    "    epochs=1,\n",
    "    logging_steps=5,\n",
    "    eval_steps=10,\n",
    "    warmup_steps=10,\n",
    "    save_steps=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    # use_cpu=True,\n",
    "    # use_wandb=True,\n",
    "    wandb_project=\"test_wandb_logging\",\n",
    "    # wandb_entity=\"bryanbriney\",\n",
    "    run_name=\"save_test_001\",\n",
    ")\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"~/Desktop/training\",\n",
    "#     logging_dir=\"~/Desktop/training/log\",\n",
    "#     per_device_train_batch_size=32,\n",
    "#     learning_rate=1e-4,\n",
    "#     max_steps=2000,\n",
    "#     gradient_accumulation_steps=1,\n",
    "#     logging_steps=10,\n",
    "#     eval_steps=50,\n",
    "#     warmup_steps=100,\n",
    "#     use_cpu=True,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=collator,\n",
    "#     train_dataset=tokenized_dataset[\"train\"],\n",
    "#     eval_dataset=tokenized_dataset[\"eval\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85291c3c41904437a870ff1b6f39c8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5     | loss: 3.1904 | lr: 0.000200\n",
      "step 10    | loss: 2.7761 | lr: 0.000400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae2141f001f445b9c06f505d78139ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< EVAL >> | loss: 2.8147 | accuracy: 0.2133 | perplexity: 15.2694\n",
      "step 15    | loss: 2.6738 | lr: 0.000305\n",
      "<< SAVING MODEL CHECKPOINT >>\n",
      "step 20    | loss: 2.6841 | lr: 0.000210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1f8fddcc6c46e3a7b97b052e4de58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< EVAL >> | loss: 2.7219 | accuracy: 0.2241 | perplexity: 13.9600\n",
      "step 25    | loss: 2.6536 | lr: 0.000114\n",
      "step 30    | loss: 2.6383 | lr: 0.000019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd056a00417844dcb669e8c69598afe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/31 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< EVAL >> | loss: 2.7187 | accuracy: 0.2252 | perplexity: 13.8820\n",
      "<< SAVING MODEL CHECKPOINT >>\n",
      "<< SAVING FINAL MODEL >>\n",
      "\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
