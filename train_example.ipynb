{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from balm.data import load_dataset, DataCollator\n",
    "from balm.models.balm import BalmForMaskedLM\n",
    "from balm.models.balm_moe import BalmMoEForMaskedLM\n",
    "from balm.models.balm_moe_rope import BalmMoERoPEForMaskedLM\n",
    "from balm.tokenizer import Tokenizer\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=\"./vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sep(txt):\n",
    "    return txt.replace(\"</s>\", \"<cls><cls>\")\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"test\": \"./balm/test_data/test_1k.txt\",\n",
    "    \"eval\": \"./balm/test_data/test_1k.txt\",\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=data_files, preprocess_fn=remove_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5927c2f610ec470299f58b377b80a122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1023ba934fd848e19d381bcba3202fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fd675a86814b7b8fdad31124358f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        x[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=320,\n",
    "    ),\n",
    "    # remove_columns=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollator(tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BalmMoERoPEForMaskedLM(\n",
    "model = BalmMoEForMaskedLM(\n",
    "    embed_dim=256,\n",
    "    ffn_dim=1024,\n",
    "    num_experts=4,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    expert_capacity=128,\n",
    "    router_z_loss_coef=0.01,\n",
    "    router_aux_loss_coef=0.01,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "\n",
    "# model =  BalmForMaskedLM(\n",
    "#     num_layers=6,\n",
    "#     num_heads=8,\n",
    "#     vocab_size=tokenizer.vocab_size,\n",
    "#     max_length=320,\n",
    "#     attention_dropout=0.1,\n",
    "#     attention_batch_first=True,\n",
    "#     layer_norm_eps=1e-5,\n",
    "# )\n",
    "\n",
    "\n",
    "# wrapped_model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=4e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18982689"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf61306b0b94314b114bb2b07fcb120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10, total Loss: 2.6946, LM loss: 2.6728, router z loss: 0.0118, router aux loss: 0.0100  \n",
      "step: 20, total Loss: 2.5289, LM loss: 2.5089, router z loss: 0.0098, router aux loss: 0.0101  \n",
      "step: 30, total Loss: 2.2836, LM loss: 2.2651, router z loss: 0.0085, router aux loss: 0.0100  \n",
      "step: 40, total Loss: 2.1535, LM loss: 2.1364, router z loss: 0.0070, router aux loss: 0.0100  \n",
      "step: 50, total Loss: 2.1300, LM loss: 2.1136, router z loss: 0.0063, router aux loss: 0.0100  \n",
      "step: 60, total Loss: 2.1334, LM loss: 2.1179, router z loss: 0.0055, router aux loss: 0.0100  \n",
      "step: 70, total Loss: 1.9980, LM loss: 1.9835, router z loss: 0.0044, router aux loss: 0.0101  \n",
      "step: 80, total Loss: 2.1106, LM loss: 2.0962, router z loss: 0.0044, router aux loss: 0.0101  \n",
      "step: 90, total Loss: 1.9247, LM loss: 1.9100, router z loss: 0.0047, router aux loss: 0.0100  \n",
      "step: 100, total Loss: 1.9263, LM loss: 1.9122, router z loss: 0.0040, router aux loss: 0.0100  \n",
      "step: 110, total Loss: 1.9217, LM loss: 1.9078, router z loss: 0.0039, router aux loss: 0.0100  \n",
      "step: 120, total Loss: 1.8960, LM loss: 1.8826, router z loss: 0.0034, router aux loss: 0.0100  \n",
      "step: 130, total Loss: 1.8619, LM loss: 1.8472, router z loss: 0.0047, router aux loss: 0.0100  \n",
      "step: 140, total Loss: 1.9723, LM loss: 1.9582, router z loss: 0.0041, router aux loss: 0.0100  \n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "model.train()\n",
    "# pbar = tqdm(total=len(train_dataloader) * train_dataloader.batch_size * n_epochs)\n",
    "pbar = tqdm(total=len(train_dataloader) * n_epochs)\n",
    "n_steps = 0\n",
    "pbar.reset()\n",
    "for epoch in range(n_epochs):\n",
    "    for examples in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        collated = collator(examples[\"input_ids\"])\n",
    "\n",
    "        input_ids = collated[\"input_ids\"].to(device)\n",
    "        labels = collated.get(\"labels\", None)\n",
    "        if labels is not None:\n",
    "            labels = labels.to(device)\n",
    "        attn_mask = collated.get(\"attention_mask\", None)\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.to(device)\n",
    "        key_padding_mask = collated.get(\"key_padding_mask\", None)\n",
    "        if key_padding_mask is not None:\n",
    "            key_padding_mask = key_padding_mask.to(device)\n",
    "\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            key_padding_mask=key_padding_mask,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # pbar.update(train_dataloader.batch_size)\n",
    "        pbar.update(1)\n",
    "        pbar.refresh()\n",
    "        n_steps += 1\n",
    "        if n_steps % 10 == 0:\n",
    "            print(\n",
    "                f\"step: {n_steps}, total Loss: {loss.item():.4f}, LM loss: {outputs.lm_loss.item():.4f}, router z loss: {outputs.router_z_loss.item():.4f}, router aux loss: {outputs.router_aux_loss.item():.4f}  \"\n",
    "            )\n",
    "            # print(\n",
    "            #     f\"step: {n_steps}, total Loss: {loss.item():.4f}  \"\n",
    "            # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
